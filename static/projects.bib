@misc{Ho:2014,
  title  = {Percymon: A Pokemon Showdown Artifical Intelligence},
  author = {Ho, Harrison and Ramesh, Varun},
  year   = {2014},
  school = {Stanford},
  url    = {https://varunramesh.net/content/documents/cs221-final-report.pdf}
}

@inproceedings{Lee:2017,
  title     = {Showdown AI competition},
  author    = {Lee, Scott and Togelius, Julian},
  booktitle = {2017 IEEE Conference on Computational Intelligence and Games (CIG)},
  year      = {2017},
  pages     = {191--198},
  doi       = {10.1109/CIG.2017.8080435},
  url       = {http://julian.togelius.com/Lee2017Showdown.pdf}
}

@misc{Rill-García:2017,
  title  = {Expert System Suitable for RPGs, Case: Pokémon},
  author = {Rill-García, Rodrigo and Madrid, Jorge},
  year   = {2017},
  url    = {https://drive.google.com/file/d/1Xq0UAkDY_5QD-6kZWd9dKVj8OFQZHkmw/preview}
}

@misc{Yu:2020,
  title  = {Graduation Project (thesis)},
  author = {Yu, Liu},
  school = {Zhejiang University City College},
  year   = {2020},
  url    = {https://github.com/blue-sky-sea/Pokemon-MCTS-AI-Master/blob/main/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%EF%BC%88%E8%AE%BA%E6%96%87%EF%BC%89%E2%80%94%E2%80%94%E5%88%98%E6%B5%A5.doc}
}

@misc{Rill-García:2018,
  title  = {Reinforcement Learning for a Turn-Based Small Scale Attrition Game},
  author = {Rill-García, Rodrigo},
  year   = {2018},
  url    = {https://ccc.inaoep.mx/~esucar/Clases-mgp/Proyectos/2018/reinforcement-learning-turn%20%281%29.pdf}
}

@misc{Kalose:2018,
  title  = {Optimal Battle Strategy in Pokemon using Reinforcement Learning},
  author = {Kalose, Akshay and Kaya, Kris and Kim, Alvin},
  year   = {2018},
  school = {Stanford},
  url    = {https://web.stanford.edu/class/aa228/reports/2018/final151.pdf}
}

@misc{Chen:2018,
  title  = {Gotta Train 'Em All: Learning to Play Pokémon Showdown with Reinforcement Learning},
  author = {Chen, Kevin and Lin, Elbert},
  year   = {2018},
  school = {Stanford},
  url    = {https://cs230.stanford.edu/projects_fall_2018/reports/12447633.pdf}
}

@inproceedings{Ihara:2018,
  author    = {Ihara, Hiroyuki and Imai, Shunsuke and Oyama, Satoshi and Kurihara, Masahito},
  title     = {Implementation and Evaluation of Information Set Monte Carlo Tree Search for Pokémon},
  booktitle = {2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  year      = {2018},
  pages     = {2182--2187},
  doi       = {10.1109/SMC.2018.00375},
  url       = {https://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/72345/1/ihara-smc2018.pdf}
}

@inproceedings{Huang:2019,
  author    = {Huang, Dan and Lee, Scott},
  title     = {A Self-Play Policy Optimization Approach to Battling Pokémon},
  booktitle = {2019 IEEE Conference on Games (CoG)},
  year      = {2019},
  pages     = {1--4},
  doi       = {10.1109/CIG.2019.8848014},
  url       = {https://www.yuzeh.com/assets/CoG-2019-Pkmn.pdf}
}

@mastersthesis{Norström:2020,
  title   = {Comparison of artificial intelligence algorithms for Pokémon battles},
  author  = {Norström, Linus},
  year    = {2020},
  school  = {Department of Space, Earth and Environment, Chalmers University Of Technology},
  address = {Gothenburg, Sweden},
  type    = {M.Sc. thesis},
  url     = {https://hdl.handle.net/20.500.12380/300015}
}

@inproceedings{Simoes:2021,
  title  = {Competitive Deep Reinforcement Learning over a Pokémon Battling Simulator},
  author = {Simoes, David and Reis, Simão and Lau, Nuno and Reis, Luís},
  year   = {2020},
  month  = {04},
  pages  = {40--45},
  doi    = {10.1109/ICARSC49921.2020.9096092},
  url    = {https://ieeexplore.ieee.org/abstract/document/9096092}
}

@inproceedings{Reis:2021,
  title     = {VGC AI Competition - A New Model of Meta-Game Balance AI Competition},
  author    = {Reis, Simão and Reis, Luís Paulo and Lau, Nuno},
  booktitle = {2021 IEEE Conference on Games (CoG)},
  year      = {2021},
  pages     = {01--08},
  doi       = {10.1109/CoG52621.2021.9618985},
  url       = {https://ludii.games/citations/COG2021-2.pdf}
}

@misc{Kyler-Wank:2021,
  title  = {CS470 Final Project: Youngster Joey AI},
  author = {Kyler-Wank, Jaden and Goldman, Drew and Shin, Peter and Shen, Alex},
  year   = {2021},
  url    = {https://github.com/alex-shen1/Youngster-Joey/blob/master/AI_Final_Paper.pdf}
}

@misc{Dell’Acqua:2022,
  title  = {Pokémon™ and Reinforcement Learning},
  author = {Dell’Acqua, Matteo},
  year   = {2022},
  url    = {https://github.com/MatteoH2O1999/alphaPoke/releases/download/delivery/Report.pdf}
}

@misc{Sarantinos:2023,
  title         = {Teamwork under extreme uncertainty: AI for Pokemon ranks 33rd in the world},
  author        = {Sarantinos, Nicholas R.},
  year          = {2023},
  eprint        = {2212.13338},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/pdf/2212.13338.pdf}
}

@misc{Tse:2022,
  title  = {Learning Competitive Pokemon through Neural Network and Reinforcement Learning},
  author = {Tse, Cyril Chun Him},
  year   = {2022},
  school = {Stanford},
  url    = {https://cs230.stanford.edu/projects_spring_2022/reports/127608668.pdf}
}

@article{Zhang:2024,
  title  = {A Simple Framework for Intrinsic Reward-Shaping for RL using LLM Feedback},
  author = {Zhang, Alex and Parashar, Ananya and Saha, Dwaipayan},
  year   = {2024},
  school = {Princeton},
  url    = {https://alexzhang13.github.io/assets/pdfs/Reward_Shaping_LLM.pdf}
}

@misc{Hu:2024,
  title         = {PokéLLMon: A Human-Parity Agent for Pokémon Battles with Large Language Models},
  author        = {Hu, Sihao and Huang, Tiansheng and Liu, Ling},
  year          = {2024},
  eprint        = {2402.01118},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/pdf/2402.01118.pdf}
}