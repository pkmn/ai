@misc{Ramesh:2014,
  title  = {Percymon: A Pokemon Showdown Artifical Intelligence},
  author = {Ho, Harrison and Ramesh, Varun},
  year   = {2014},
  school = {Stanford},
  url    = {https://varunramesh.net/content/documents/cs221-final-report.pdf}
}

@inproceedings{Lee:2017,
  title     = {Showdown AI competition},
  author    = {Lee, Scott and Togelius, Julian},
  booktitle = {2017 IEEE Conference on Computational Intelligence and Games (CIG)},
  year      = {2017},
  pages     = {191--198},
  doi       = {10.1109/CIG.2017.8080435},
  url       = {http://julian.togelius.com/Lee2017Showdown.pdf}
}

@misc{Kalose:2018,
  title  = {Optimal Battle Strategy in Pokemon using Reinforcement Learning},
  author = {Kalose, Akshay and Kaya, Kris and Kim, Alvin},
  year   = {2018},
  school = {Stanford},
  url    = {https://web.stanford.edu/class/aa228/reports/2018/final151.pdf}
}

@misc{Chen:2018,
  title  = {Gotta Train 'Em All: Learning to Play Pokémon Showdown with Reinforcement Learning},
  author = {Chen, Kevin and Lin, Elbert},
  year   = {2018},
  school = {Stanford},
  url    = {https://cs230.stanford.edu/projects_fall_2018/reports/12447633.pdf}
}

@inproceedings{Ihara:2018,
  author    = {Ihara, Hiroyuki and Imai, Shunsuke and Oyama, Satoshi and Kurihara, Masahito},
  title     = {Implementation and Evaluation of Information Set Monte Carlo Tree Search for Pokémon},
  booktitle = {2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  year      = {2018},
  pages     = {2182--2187},
  doi       = {10.1109/SMC.2018.00375},
  url       = {https://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/72345/1/ihara-smc2018.pdf}
}

@inproceedings{Huang:2019,
  author    = {Huang, Dan and Lee, Scott},
  title     = {A Self-Play Policy Optimization Approach to Battling Pokémon},
  booktitle = {2019 IEEE Conference on Games (CoG)},
  year      = {2019},
  pages     = {1--4},
  doi       = {10.1109/CIG.2019.8848014},
  url       = {https://www.yuzeh.com/assets/CoG-2019-Pkmn.pdf}
}

@mastersthesis{Norström:2020,
  title   = {Comparison of artificial intelligence algorithms for Pokémon battles},
  author  = {Norström, Linus},
  year    = {2020},
  school  = {Department of Space, Earth and Environment, Chalmers University Of Technology},
  address = {Gothenburg, Sweden},
  type    = {M.Sc. thesis},
  url     = {https://hdl.handle.net/20.500.12380/300015}
}

@inproceedings{Simoes:2021,
  title  = {Competitive Deep Reinforcement Learning over a Pokémon Battling Simulator},
  author = {Simoes, David and Reis, Simão and Lau, Nuno and Reis, Luís},
  year   = {2020},
  month  = {04},
  pages  = {40--45},
  doi    = {10.1109/ICARSC49921.2020.9096092},
  url    = {https://www.researchgate.net/publication/341497785_Competitive_Deep_Reinforcement_Learning_over_a_Pokemon_Battling_Simulator}
}

@inproceedings{Reis:2021,
  title     = {VGC AI Competition - A New Model of Meta-Game Balance AI Competition},
  author    = {Reis, Simão and Reis, Luís Paulo and Lau, Nuno},
  booktitle = {2021 IEEE Conference on Games (CoG)},
  year      = {2021},
  pages     = {01--08},
  doi       = {10.1109/CoG52621.2021.9618985},
  url       = {https://ludii.games/citations/COG2021-2.pdf}
}

@misc{Sarantinos:2023,
  title         = {Teamwork under extreme uncertainty: AI for Pokemon ranks 33rd in the world},
  author        = {Sarantinos, Nicholas R.},
  year          = {2023},
  eprint        = {2212.13338},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/pdf/2212.13338.pdf}
}

@misc{Tse:2022,
  title  = {Learning Competitive Pokemon through Neural Network and Reinforcement Learning},
  author = {Tse, Cyril Chun Him},
  year   = {2022},
  school = {Stanford},
  url    = {https://cs230.stanford.edu/projects_spring_2022/reports/127608668.pdf}
}
